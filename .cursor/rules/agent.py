import subprocess
import shutil
import sys
import argparse
from typing import Optional

def _check_ollama_available() -> bool:
    return shutil.which("ollama") is not None


def start_llama3(model: str = "llama3") -> None:
    if not _check_ollama_available():
        print("âŒ Hata: 'ollama' komutu bulunamadÄ±. LÃ¼tfen Ollama'yÄ± kurun: https://ollama.com")
        return
    print(f"ğŸ¤– {model} baÅŸlatÄ±lÄ±yor...")
    try:
        subprocess.Popen(["ollama", "run", model])
    except Exception as exc:
        print(f"âŒ Model baÅŸlatÄ±lÄ±rken hata: {exc}")

def prompt_to_llama(prompt: str, model: str = "llama3", timeout_sec: int = 120) -> str:
    if not _check_ollama_available():
        return "Hata: Ollama yÃ¼klÃ¼ deÄŸil veya PATH'te bulunamadÄ±."
    print("ğŸ“¤ Mesaj gÃ¶nderiliyor...")
    try:
        result = subprocess.run(
            ["ollama", "run", model],
            input=prompt.encode(),
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            timeout=timeout_sec,
        )
        if result.returncode != 0:
            err = result.stderr.decode(errors="ignore")
            return f"Model Ã§alÄ±ÅŸtÄ±rma hatasÄ± (code={result.returncode}): {err.strip()}"
        return result.stdout.decode()
    except subprocess.TimeoutExpired:
        return "Zaman aÅŸÄ±mÄ±: Model yanÄ±tÄ± belirtilen sÃ¼re iÃ§inde gelmedi."
    except Exception as exc:
        return f"Beklenmeyen hata: {exc}"

def _build_default_prompt() -> str:
    return (
        "PsyClinic AI â€“ MVP iÃ§in ilk sprint hedefi:\n"
        "1. KullanÄ±cÄ± kayÄ±t ve giriÅŸ sistemi (email, Google, Apple)\n"
        "2. Randevu modÃ¼lÃ¼ (psikolog seÃ§imi, tarih, saat)\n"
        "3. Seans ekranÄ± (AI destekli not alma)\n"
        "4. PDF Ã§Ä±ktÄ±sÄ± (terapi notlarÄ±)\n"
        "5. Firestore backend baÄŸlantÄ±sÄ±\n\n "
        "ğŸ”§ Bu sprint iÃ§in en uygun gÃ¶rev planlamasÄ±nÄ± Ã§Ä±kar ve her gÃ¶rev iÃ§in adÄ±m adÄ±m yapÄ±lacaklarÄ± yaz."
    )


def main(argv: Optional[list[str]] = None) -> int:
    parser = argparse.ArgumentParser(description="PsyClinicAI ajanÄ±")
    parser.add_argument("--model", default="llama3", help="Ollama model adÄ± (Ã¶rn. llama3, llama3.1, qwen2)")
    parser.add_argument("--prompt", default=None, help="Ã–zel prompt (boÅŸsa varsayÄ±lan kullanÄ±lÄ±r)")
    parser.add_argument("--timeout", type=int, default=120, help="YanÄ±t iÃ§in zaman aÅŸÄ±mÄ± (saniye)")
    parser.add_argument("--start-only", action="store_true", help="Sadece modeli baÅŸlat, prompt gÃ¶nderme")

    args = parser.parse_args(argv)

    if args.start_only:
        start_llama3(args.model)
        return 0

    prompt = args.prompt or _build_default_prompt()
    print("ğŸš€ AI ajan gÃ¶reve baÅŸlÄ±yor...\n")
    response = prompt_to_llama(prompt, model=args.model, timeout_sec=args.timeout)
    print("ğŸ“¥ Gelen yanÄ±t:\n")
    print(response)
    return 0


if __name__ == "__main__":
    raise SystemExit(main())